{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting and organizing data from the WeRateDogs twitter handle turned out to be a difficult and time-consuming task, but it was also a great learning experience. I first obtained the unclean twitter_archives dataset through manual download, which was relatively easy. However, I then had to programmatically download the image_predictions tsv file from a provided url using the requests library. This required me to navigate through the file content by using the get function on the url and then writing that content to an empty file.\n",
    "\n",
    "The most challenging part of this project was gathering data from the twitter API for each tweet. To do this, I had to set up an application and use unique keys to access the API with the help of the tweepy library. This was a new experience for me and I had to spend some time learning how to set up the application and connect it to my twitter account to get the unique keys. Once I had the keys, I used the library's get_status function on each and every tweet id to get the content of each tweet. I then converted this content to the json format for future use and wrote it to a text file called tweet_json. Doing all this for every tweet required me to use a 'for' loop, which was time-consuming and required a lot of attention to detail.\n",
    "\n",
    "After gathering all three datasets, I assessed and cleaned them for any quality and tidiness issues. The twitter archives table had the most issues as it was the largest of the 3 tables and had a lot of features regarding the tweets like tweet text, date and time of the tweet, etc. A lot of the issues could just be spotted by the naked eye thanks to pandas functions like head, tail and sample. Others required a little more analysis, mainly through summaries or filtering out certain sections of the data and evaluating the features. The info and value_counts functions were frequently used for the same. Most of the tidiness issues involved joining of the tables and melting certain features into a single column.\n",
    "\n",
    "The final part of this project was the most code-oriented, which was cleaning. For each operation, I used the define, code and test format. I first defined the operation I wanted to perform, then wrote the code for it and finally conducted tests on the dataset to see if that particular operation was performed. Various pandas functions were used, some in isolation and some together. A lot of the operations involved extracting data from certain features and replacing the inaccurate or incomplete column data with that data. A lot of unwanted rows and columns, especially the ones with retweets, were removed.\n",
    "\n",
    "In conclusion, this project was a great learning experience. It allowed me to gain experience in handling problems that arise when creating custom datasets, finding out the various quality and tidiness-related issues, and then cleaning up those issues to make the datasets analysis-worthy. It also helped me develop an intuition about the various functions that can be combined together to perform what might seem as really cumbersome or undoable tasks. Overall, I am glad that I took on this challenge and would recommend it to anyone looking to improve their data wrangling skills.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
